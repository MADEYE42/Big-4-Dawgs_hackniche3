{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T23:48:34.099625Z",
     "start_time": "2025-03-08T23:47:47.982649Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install psycopg2-binary elasticsearch scikit-learn",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\abhirat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.9.10)\n",
      "Requirement already satisfied: elasticsearch in c:\\users\\abhirat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (8.17.2)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in c:\\users\\abhirat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from elasticsearch) (8.17.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\abhirat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn) (2.2.0)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in c:\\users\\abhirat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.2.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\abhirat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2024.12.14)\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Recommendation System\n",
    "This notebook implements a recommendation system using PostgreSQL for product data and Elasticsearch for user history."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T23:49:43.081491Z",
     "start_time": "2025-03-08T23:49:42.873425Z"
    }
   },
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import string\n",
    "import psycopg2\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "DB_PARAMS = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"database\": \"ShopMartDB\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"port\": \"5432\"\n",
    "}\n",
    "\n",
    "# Elasticsearch connection\n",
    "ES_CLIENT = Elasticsearch(\"http://localhost:9200\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T23:49:53.672602Z",
     "start_time": "2025-03-08T23:49:53.655898Z"
    }
   },
   "source": [
    "def get_db_connection():\n",
    "    return psycopg2.connect(**DB_PARAMS)\n",
    "\n",
    "def load_data_from_postgres():\n",
    "    conn = get_db_connection()\n",
    "    query = \"\"\"\n",
    "        SELECT asin, title, price, rating, category, discount, reviews_count, prime\n",
    "        FROM amazon_products\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T23:50:07.844652Z",
     "start_time": "2025-03-08T23:50:07.824397Z"
    }
   },
   "source": [
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = ' '.join(text.split())\n",
    "    simple_stopwords = {\n",
    "        'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n",
    "    }\n",
    "    text = ' '.join([word for word in text.split() if word not in simple_stopwords])\n",
    "    return text\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "    df['discount'] = df['discount'].replace(\"No Discount\", 0)\n",
    "    df['discount'] = pd.to_numeric(df['discount'], errors='coerce')\n",
    "    df['discount'] = df['discount'].fillna(0)\n",
    "    if df['price'].dtype == object:\n",
    "        df['price'] = df['price'].replace('[\\₹,$,£,€,]', '', regex=True).astype(str).str.replace(',', '')\n",
    "        df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "    df['price'] = df['price'].fillna(df['price'].median())\n",
    "    df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "    df['rating'] = df['rating'].fillna(df['rating'].median())\n",
    "    df['reviews_count'] = pd.to_numeric(df['reviews_count'], errors='coerce')\n",
    "    df['reviews_count'] = df['reviews_count'].fillna(0)\n",
    "    df['processed_title'] = df['title'].apply(preprocess_text)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T23:50:19.561274Z",
     "start_time": "2025-03-08T23:50:19.439831Z"
    }
   },
   "source": [
    "def create_content_representation(df):\n",
    "    def create_feature_soup(row):\n",
    "        features = []\n",
    "        prime_status = 'prime' if row.get('prime') == 1 else 'not_prime'\n",
    "        features.append(prime_status)\n",
    "        if isinstance(row.get('category'), str):\n",
    "            category = row.get('category').lower().replace(' ', '_')\n",
    "            features.append(f\"category_{category}\")\n",
    "        if row['price'] < 500:\n",
    "            price_range = 'budget_price'\n",
    "        elif row['price'] < 7500:\n",
    "            price_range = 'mid_price'\n",
    "        else:\n",
    "            price_range = 'premium_price'\n",
    "        features.append(price_range)\n",
    "        if row['rating'] >= 4.5:\n",
    "            rating_range = 'top_rated'\n",
    "        elif row['rating'] >= 4.0:\n",
    "            rating_range = 'highly_rated'\n",
    "        elif row['rating'] >= 3.0:\n",
    "            rating_range = 'average_rated'\n",
    "        else:\n",
    "            rating_range = 'low_rated'\n",
    "        features.append(rating_range)\n",
    "        if row['discount'] >= 30:\n",
    "            discount_range = 'high_discount'\n",
    "        elif row['discount'] >= 10:\n",
    "            discount_range = 'medium_discount'\n",
    "        else:\n",
    "            discount_range = 'low_discount'\n",
    "        features.append(discount_range)\n",
    "        if row['reviews_count'] > 1000:\n",
    "            popularity = 'very_popular'\n",
    "        elif row['reviews_count'] > 100:\n",
    "            popularity = 'popular'\n",
    "        else:\n",
    "            popularity = 'less_popular'\n",
    "        features.append(popularity)\n",
    "        return ' '.join(features)\n",
    "    df['feature_soup'] = df.apply(create_feature_soup, axis=1)\n",
    "    return df\n",
    "\n",
    "def extract_camera_terms(title):\n",
    "    if not isinstance(title, str):\n",
    "        return \"\"\n",
    "    camera_terms = [\n",
    "        'dslr', 'mirrorless', 'canon', 'nikon', 'sony', 'fujifilm', 'olympus', 'panasonic',\n",
    "    ]\n",
    "    title_lower = title.lower()\n",
    "    found_terms = []\n",
    "    for term in camera_terms:\n",
    "        if term in title_lower:\n",
    "            found_terms.append(term)\n",
    "    model_patterns = [\n",
    "        r'\\b[a-z]+\\d+[a-z]*\\b',\n",
    "        r'\\b\\d+[a-z]+\\b',\n",
    "        r'\\bmark\\s+[ivx]+\\b',\n",
    "    ]\n",
    "    for pattern in model_patterns:\n",
    "        matches = re.findall(pattern, title_lower)\n",
    "        found_terms.extend(matches)\n",
    "    return ' '.join(found_terms)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T23:50:27.103717Z",
     "start_time": "2025-03-08T23:50:26.970386Z"
    }
   },
   "source": [
    "def build_recommendation_model(df):\n",
    "    if 'processed_title' not in df.columns:\n",
    "        df['processed_title'] = df['title'].apply(preprocess_text)\n",
    "    df['camera_terms'] = df['title'].apply(extract_camera_terms)\n",
    "    title_tfidf = TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2)\n",
    "    )\n",
    "    title_tfidf_matrix = title_tfidf.fit_transform(df['processed_title'])\n",
    "    camera_tfidf = TfidfVectorizer(stop_words='english')\n",
    "    if df['camera_terms'].str.strip().str.len().sum() > 0:\n",
    "        camera_tfidf_matrix = camera_tfidf.fit_transform(df['camera_terms'])\n",
    "        has_camera_terms = True\n",
    "    else:\n",
    "        camera_tfidf_matrix = title_tfidf_matrix.copy()\n",
    "        has_camera_terms = False\n",
    "    feature_tfidf = TfidfVectorizer(stop_words='english')\n",
    "    feature_tfidf_matrix = feature_tfidf.fit_transform(df['feature_soup'])\n",
    "    title_sim = cosine_similarity(title_tfidf_matrix, title_tfidf_matrix)\n",
    "    feature_sim = cosine_similarity(feature_tfidf_matrix, feature_tfidf_matrix)\n",
    "    if has_camera_terms:\n",
    "        camera_sim = cosine_similarity(camera_tfidf_matrix, camera_tfidf_matrix)\n",
    "        combined_sim = 0.5 * title_sim + 0.3 * camera_sim + 0.2 * feature_sim\n",
    "    else:\n",
    "        combined_sim = 0.7 * title_sim + 0.3 * feature_sim\n",
    "    return combined_sim\n",
    "\n",
    "def get_recommendations(product_idx, cosine_sim, df, top_n=5):\n",
    "    try:\n",
    "        if product_idx < 0 or product_idx >= len(df):\n",
    "            print(f\"Product index {product_idx} is out of range (0-{len(df)-1}).\")\n",
    "            return pd.DataFrame()\n",
    "        sim_scores = list(enumerate(cosine_sim[product_idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1:top_n+1]\n",
    "        product_indices = [i[0] for i in sim_scores]\n",
    "        columns_to_include = ['asin', 'title', 'price', 'rating', 'category', 'discount', 'reviews_count']\n",
    "        available_columns = [col for col in columns_to_include if col in df.columns]\n",
    "        recommendations = df.iloc[product_indices][available_columns].copy()\n",
    "        recommendations['similarity_score'] = [score for _, score in sim_scores]\n",
    "        return recommendations\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting recommendations: {e}\")\n",
    "        return pd.DataFrame()"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History-based Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T23:50:36.748168Z",
     "start_time": "2025-03-08T23:50:36.739954Z"
    }
   },
   "source": [
    "def get_recommendations_from_history(user_history, df, top_n=9):\n",
    "    if not user_history or len(user_history) == 0:\n",
    "        return pd.DataFrame()\n",
    "    processed_df = preprocess_data(df)\n",
    "    content_df = create_content_representation(processed_df)\n",
    "    combined_sim = build_recommendation_model(content_df)\n",
    "    history_indices = []\n",
    "    for asin in user_history:\n",
    "        indices = content_df.index[content_df['asin'] == asin].tolist()\n",
    "        if indices:\n",
    "            history_indices.append(indices[0])\n",
    "    if not history_indices:\n",
    "        return pd.DataFrame()\n",
    "    all_recommendations = pd.DataFrame()\n",
    "    for idx in history_indices:\n",
    "        recommendations = get_recommendations(idx, combined_sim, content_df, top_n)\n",
    "        if all_recommendations.empty:\n",
    "            all_recommendations = recommendations\n",
    "        else:\n",
    "            all_recommendations = pd.concat([all_recommendations, recommendations])\n",
    "    all_recommendations = all_recommendations.sort_values('similarity_score', ascending=False)\n",
    "    all_recommendations = all_recommendations.drop_duplicates(subset='asin')\n",
    "    return all_recommendations.head(top_n)\n",
    "\n",
    "def get_user_history_from_elasticsearch(user_id):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"term\": {\n",
    "                \"user_id\": user_id\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = ES_CLIENT.search(index=\"user_history\", body=query)\n",
    "    history = [hit[\"_source\"][\"product_asin\"] for hit in response[\"hits\"][\"hits\"]]\n",
    "    return history"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T23:50:45.566107Z",
     "start_time": "2025-03-08T23:50:42.163303Z"
    }
   },
   "source": [
    "# Load data\n",
    "df = load_data_from_postgres()\n",
    "\n",
    "# Example 1: Product-based recommendations\n",
    "asin = \"B08J5W9C9Q\"\n",
    "top_n = 5\n",
    "product_idx = df.index[df['asin'] == asin].tolist()\n",
    "if product_idx:\n",
    "    processed_df = preprocess_data(df)\n",
    "    content_df = create_content_representation(processed_df)\n",
    "    combined_sim = build_recommendation_model(content_df)\n",
    "    recommendations = get_recommendations(product_idx[0], combined_sim, content_df, top_n)\n",
    "    display(recommendations)\n",
    "\n",
    "# Example 2: History-based recommendations\n",
    "user_id = \"user123\"\n",
    "user_history = get_user_history_from_elasticsearch(user_id)\n",
    "history_recommendations = get_recommendations_from_history(user_history, df, top_n=5)\n",
    "display(history_recommendations)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhirat\\AppData\\Local\\Temp\\ipykernel_22248\\2824819319.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n        SELECT asin, title, price, rating, category, discount, reviews_count, prime\n        FROM amazon_products\n    ': column \"reviews_count\" does not exist\nLINE 2: ...T asin, title, price, rating, category, discount, reviews_co...\n                                                             ^\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUndefinedColumn\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\sql.py:2674\u001B[0m, in \u001B[0;36mSQLiteDatabase.execute\u001B[1;34m(self, sql, params)\u001B[0m\n\u001B[0;32m   2673\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 2674\u001B[0m     \u001B[43mcur\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2675\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cur\n",
      "\u001B[1;31mUndefinedColumn\u001B[0m: column \"reviews_count\" does not exist\nLINE 2: ...T asin, title, price, rating, category, discount, reviews_co...\n                                                             ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mDatabaseError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Load data\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mload_data_from_postgres\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Example 1: Product-based recommendations\u001B[39;00m\n\u001B[0;32m      5\u001B[0m asin \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mB08J5W9C9Q\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "Cell \u001B[1;32mIn[7], line 10\u001B[0m, in \u001B[0;36mload_data_from_postgres\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m conn \u001B[38;5;241m=\u001B[39m get_db_connection()\n\u001B[0;32m      6\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;124m    SELECT asin, title, price, rating, category, discount, reviews_count, prime\u001B[39m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;124m    FROM amazon_products\u001B[39m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;124m\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m---> 10\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_sql_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m conn\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\sql.py:526\u001B[0m, in \u001B[0;36mread_sql_query\u001B[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001B[0m\n\u001B[0;32m    523\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m dtype_backend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mno_default\n\u001B[0;32m    525\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pandasSQL_builder(con) \u001B[38;5;28;01mas\u001B[39;00m pandas_sql:\n\u001B[1;32m--> 526\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpandas_sql\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_query\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m        \u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    528\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_col\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    529\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    530\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcoerce_float\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcoerce_float\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    531\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    532\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    533\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    534\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    535\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\sql.py:2738\u001B[0m, in \u001B[0;36mSQLiteDatabase.read_query\u001B[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001B[0m\n\u001B[0;32m   2727\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_query\u001B[39m(\n\u001B[0;32m   2728\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   2729\u001B[0m     sql,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2736\u001B[0m     dtype_backend: DtypeBackend \u001B[38;5;241m|\u001B[39m Literal[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2737\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Iterator[DataFrame]:\n\u001B[1;32m-> 2738\u001B[0m     cursor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2739\u001B[0m     columns \u001B[38;5;241m=\u001B[39m [col_desc[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m col_desc \u001B[38;5;129;01min\u001B[39;00m cursor\u001B[38;5;241m.\u001B[39mdescription]\n\u001B[0;32m   2741\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\sql.py:2686\u001B[0m, in \u001B[0;36mSQLiteDatabase.execute\u001B[1;34m(self, sql, params)\u001B[0m\n\u001B[0;32m   2683\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ex \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01minner_exc\u001B[39;00m\n\u001B[0;32m   2685\u001B[0m ex \u001B[38;5;241m=\u001B[39m DatabaseError(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecution failed on sql \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msql\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 2686\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m ex \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mexc\u001B[39;00m\n",
      "\u001B[1;31mDatabaseError\u001B[0m: Execution failed on sql '\n        SELECT asin, title, price, rating, category, discount, reviews_count, prime\n        FROM amazon_products\n    ': column \"reviews_count\" does not exist\nLINE 2: ...T asin, title, price, rating, category, discount, reviews_co...\n                                                             ^\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
