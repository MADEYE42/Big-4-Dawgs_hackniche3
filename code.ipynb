{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>delivery</th>\n",
       "      <th>discount</th>\n",
       "      <th>image_url</th>\n",
       "      <th>original_price</th>\n",
       "      <th>price</th>\n",
       "      <th>prime</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews_count</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0DQXGCPFJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(80% off)</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71W+dSyLXA...</td>\n",
       "      <td>₹6,999</td>\n",
       "      <td>₹1,399</td>\n",
       "      <td>No</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2025-03-08 15:59:54</td>\n",
       "      <td>Sponsored Ad - SIRGAWAIN Action Camera 1080P 1...</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "      <td>cameras</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0CVX3CXDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(36% off)</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71Tdji2e5c...</td>\n",
       "      <td>₹10,999</td>\n",
       "      <td>₹6,999</td>\n",
       "      <td>No</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2025-03-08 15:59:54</td>\n",
       "      <td>Sponsored Ad - IZI Click Plus 5K 30FPS Budget ...</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "      <td>cameras</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0DQXGCPFJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(80% off)</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71W+dSyLXA...</td>\n",
       "      <td>₹6,999</td>\n",
       "      <td>₹1,399</td>\n",
       "      <td>No</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>2025-03-08 15:59:54</td>\n",
       "      <td>SIRGAWAIN Action Camera 1080P 12MP Sports Came...</td>\n",
       "      <td>https://www.amazon.in/SIRGAWAIN-Camera-Underwa...</td>\n",
       "      <td>cameras</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0CS6JDM78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(42% off)</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61ynVFrjIJ...</td>\n",
       "      <td>₹25,990</td>\n",
       "      <td>₹14,990</td>\n",
       "      <td>No</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>2025-03-08 15:59:54</td>\n",
       "      <td>DJI Action 2 Power Combo (128GB), Action Camer...</td>\n",
       "      <td>https://www.amazon.in/DJI-Super-Wide-Attachmen...</td>\n",
       "      <td>cameras</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0D32V55RP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(47% off)</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71qsysJOL6...</td>\n",
       "      <td>₹16,990</td>\n",
       "      <td>₹8,998</td>\n",
       "      <td>No</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>2025-03-08 15:59:54</td>\n",
       "      <td>FitSpark Eagle i15 PRO MAX Real 4K30FPS Dual T...</td>\n",
       "      <td>https://www.amazon.in/FitSpark-EAGLE-i15-PRO-M...</td>\n",
       "      <td>cameras</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin delivery   discount  \\\n",
       "0  B0DQXGCPFJ      NaN  (80% off)   \n",
       "1  B0CVX3CXDB      NaN  (36% off)   \n",
       "2  B0DQXGCPFJ      NaN  (80% off)   \n",
       "3  B0CS6JDM78      NaN  (42% off)   \n",
       "4  B0D32V55RP      NaN  (47% off)   \n",
       "\n",
       "                                           image_url original_price    price  \\\n",
       "0  https://m.media-amazon.com/images/I/71W+dSyLXA...         ₹6,999   ₹1,399   \n",
       "1  https://m.media-amazon.com/images/I/71Tdji2e5c...        ₹10,999   ₹6,999   \n",
       "2  https://m.media-amazon.com/images/I/71W+dSyLXA...         ₹6,999   ₹1,399   \n",
       "3  https://m.media-amazon.com/images/I/61ynVFrjIJ...        ₹25,990  ₹14,990   \n",
       "4  https://m.media-amazon.com/images/I/71qsysJOL6...        ₹16,990   ₹8,998   \n",
       "\n",
       "  prime  rating reviews_count sponsored            timestamp  \\\n",
       "0    No     3.5             0       Yes  2025-03-08 15:59:54   \n",
       "1    No     3.2             0       Yes  2025-03-08 15:59:54   \n",
       "2    No     3.5             0        No  2025-03-08 15:59:54   \n",
       "3    No     4.2             0        No  2025-03-08 15:59:54   \n",
       "4    No     4.7             0        No  2025-03-08 15:59:54   \n",
       "\n",
       "                                               title  \\\n",
       "0  Sponsored Ad - SIRGAWAIN Action Camera 1080P 1...   \n",
       "1  Sponsored Ad - IZI Click Plus 5K 30FPS Budget ...   \n",
       "2  SIRGAWAIN Action Camera 1080P 12MP Sports Came...   \n",
       "3  DJI Action 2 Power Combo (128GB), Action Camer...   \n",
       "4  FitSpark Eagle i15 PRO MAX Real 4K30FPS Dual T...   \n",
       "\n",
       "                                                 url category  page  \n",
       "0  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  cameras   NaN  \n",
       "1  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  cameras   NaN  \n",
       "2  https://www.amazon.in/SIRGAWAIN-Camera-Underwa...  cameras   NaN  \n",
       "3  https://www.amazon.in/DJI-Super-Wide-Attachmen...  cameras   NaN  \n",
       "4  https://www.amazon.in/FitSpark-EAGLE-i15-PRO-M...  cameras   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"data_scrape\\\\merged_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['page'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                 0\n",
       "delivery           962\n",
       "discount           137\n",
       "image_url            0\n",
       "original_price      48\n",
       "price               47\n",
       "prime                0\n",
       "rating             114\n",
       "reviews_count       32\n",
       "sponsored         1003\n",
       "timestamp         2095\n",
       "title                0\n",
       "url                207\n",
       "category             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['sponsored', 'url', 'asin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delivery           962\n",
       "discount           137\n",
       "image_url            0\n",
       "original_price      48\n",
       "price               47\n",
       "prime                0\n",
       "rating             114\n",
       "reviews_count       32\n",
       "timestamp         2095\n",
       "title                0\n",
       "category             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['delivery', 'original_price', 'timestamp', 'image_url'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discount         137\n",
       "price             47\n",
       "prime              0\n",
       "rating           114\n",
       "reviews_count     32\n",
       "title              0\n",
       "category           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount</th>\n",
       "      <th>price</th>\n",
       "      <th>prime</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews_count</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(80% off)</td>\n",
       "      <td>₹1,399</td>\n",
       "      <td>No</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>Sponsored Ad - SIRGAWAIN Action Camera 1080P 1...</td>\n",
       "      <td>cameras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(36% off)</td>\n",
       "      <td>₹6,999</td>\n",
       "      <td>No</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sponsored Ad - IZI Click Plus 5K 30FPS Budget ...</td>\n",
       "      <td>cameras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(80% off)</td>\n",
       "      <td>₹1,399</td>\n",
       "      <td>No</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>SIRGAWAIN Action Camera 1080P 12MP Sports Came...</td>\n",
       "      <td>cameras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(42% off)</td>\n",
       "      <td>₹14,990</td>\n",
       "      <td>No</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0</td>\n",
       "      <td>DJI Action 2 Power Combo (128GB), Action Camer...</td>\n",
       "      <td>cameras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(47% off)</td>\n",
       "      <td>₹8,998</td>\n",
       "      <td>No</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>FitSpark Eagle i15 PRO MAX Real 4K30FPS Dual T...</td>\n",
       "      <td>cameras</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    discount    price prime  rating reviews_count  \\\n",
       "0  (80% off)   ₹1,399    No     3.5             0   \n",
       "1  (36% off)   ₹6,999    No     3.2             0   \n",
       "2  (80% off)   ₹1,399    No     3.5             0   \n",
       "3  (42% off)  ₹14,990    No     4.2             0   \n",
       "4  (47% off)   ₹8,998    No     4.7             0   \n",
       "\n",
       "                                               title category  \n",
       "0  Sponsored Ad - SIRGAWAIN Action Camera 1080P 1...  cameras  \n",
       "1  Sponsored Ad - IZI Click Plus 5K 30FPS Budget ...  cameras  \n",
       "2  SIRGAWAIN Action Camera 1080P 12MP Sports Came...  cameras  \n",
       "3  DJI Action 2 Power Combo (128GB), Action Camer...  cameras  \n",
       "4  FitSpark Eagle i15 PRO MAX Real 4K30FPS Dual T...  cameras  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONTENT BASED FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "Creating content representation...\n",
      "Building recommendation model...\n",
      "\n",
      "Example Product (Index 1446):\n",
      "Title: WOW Imagine Shock Proof Clear Back Case Mobile Cover for Samsung Galaxy M14 5G (Hard | Hybrid PC + TPU | Full Armour Device & Camera Protection | Black)\n",
      "Price: $145.00\n",
      "Rating: 4.1\n",
      "Category: mobile_back_covers\n",
      "Discount: 85.0%\n",
      "Reviews Count: 1231.0\n",
      "\n",
      "Getting recommendations...\n",
      "\n",
      "Top 5 Recommended Products:\n",
      "\n",
      "Recommendation 1 (Index 1446):\n",
      "Title: WOW Imagine Shock Proof Clear Back Case Mobile Cover for Samsung Galaxy M14 5G (Hard | Hybrid PC + TPU | Full Armour Device & Camera Protection | Black)\n",
      "Price: 145.0\n",
      "Rating: 4.1\n",
      "Category: mobile_back_covers\n",
      "Discount: 85.0\n",
      "Reviews_count: 1231.0\n",
      "Similarity Score: 1.0000\n",
      "\n",
      "Recommendation 2 (Index 1365):\n",
      "Title: WOW IMAGINE Shock Proof Clear Back Case Mobile Cover for Realme GT Neo 3 5G (Hard | Hybrid PC + TPU | Full Armour Device & Camera Protection | Black)\n",
      "Price: 195.0\n",
      "Rating: 4.2\n",
      "Category: mobile_back_covers\n",
      "Discount: 80.0\n",
      "Reviews_count: 137.0\n",
      "Similarity Score: 0.6691\n",
      "\n",
      "Recommendation 3 (Index 1181):\n",
      "Title: TheGiftKart Shockproof Crystal Clear Back Cover Case for Samsung Galaxy M14 5G | 360 Degree Protection | Protective Design | Transparent Back (PC & TPU | Black Bumper)\n",
      "Price: 149.0\n",
      "Rating: 4.3\n",
      "Category: mobile_back_covers\n",
      "Discount: 85.0\n",
      "Reviews_count: 1899.0\n",
      "Similarity Score: 0.6321\n",
      "\n",
      "Recommendation 4 (Index 1232):\n",
      "Title: BASECASE Shock Proof Crystal Clear Back Case Mobile Cover for 1+ OnePlus Nord CE 3 Lite 5G (Hard | Hybrid PC + TPU | Full Armour Device & Camera Protection | Black)\n",
      "Price: 179.0\n",
      "Rating: 4.2\n",
      "Category: mobile_back_covers\n",
      "Discount: 82.0\n",
      "Reviews_count: 753.0\n",
      "Similarity Score: 0.5971\n",
      "\n",
      "Recommendation 5 (Index 1203):\n",
      "Title: WOW IMAGINE Shock Proof Clear Back Case Mobile Cover for Xiaomi Redmi 13C 5G | Poco M6 5G (Hard | Hybrid PC + TPU | Full Armour Device & Camera Protection | Black)\n",
      "Price: 189.0\n",
      "Rating: 4.3\n",
      "Category: mobile_back_covers\n",
      "Discount: 81.0\n",
      "Reviews_count: 395.0\n",
      "Similarity Score: 0.5879\n",
      "\n",
      "Recommendation similarity visualization saved as 'recommendation_similarity.png'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Simple text preprocessing function without NLTK\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Simple stopwords list (common English stopwords)\n",
    "    simple_stopwords = {\n",
    "        'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n",
    "        'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "        'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from',\n",
    "        'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\n",
    "        'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any',\n",
    "        'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor',\n",
    "        'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can',\n",
    "        'will', 'just', 'don', 'should', 'now', 'i', 'me', 'my', 'myself', 'we',\n",
    "        'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves',\n",
    "        'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its',\n",
    "        'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',\n",
    "        'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was',\n",
    "        'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "        'did', 'doing', 'would', 'should', 'could', 'ought', 'i\\'m', 'you\\'re',\n",
    "        'he\\'s', 'she\\'s', 'it\\'s', 'we\\'re', 'they\\'re', 'i\\'ve', 'you\\'ve',\n",
    "        'we\\'ve', 'they\\'ve', 'i\\'d', 'you\\'d', 'he\\'d', 'she\\'d', 'we\\'d',\n",
    "        'they\\'d', 'i\\'ll', 'you\\'ll', 'he\\'ll', 'she\\'ll', 'we\\'ll', 'they\\'ll',\n",
    "        'isn\\'t', 'aren\\'t', 'wasn\\'t', 'weren\\'t', 'hasn\\'t', 'haven\\'t', 'hadn\\'t',\n",
    "        'doesn\\'t', 'don\\'t', 'didn\\'t', 'won\\'t', 'wouldn\\'t', 'shan\\'t', 'shouldn\\'t',\n",
    "        'can\\'t', 'cannot', 'couldn\\'t', 'mustn\\'t', 'let\\'s', 'that\\'s', 'who\\'s',\n",
    "        'what\\'s', 'here\\'s', 'there\\'s', 'when\\'s', 'where\\'s', 'why\\'s', 'how\\'s'\n",
    "    }\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in simple_stopwords])\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Data preprocessing\n",
    "def preprocess_data(df):\n",
    "    # Make a copy to avoid modifying the original dataframe\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Handle the 'discount' column\n",
    "    df['discount'] = df['discount'].replace(\"No Discount\", 0)\n",
    "    df['discount'] = pd.to_numeric(df['discount'], errors='coerce')\n",
    "    df['discount'] = df['discount'].fillna(0)\n",
    "    \n",
    "    # Fix price column - remove currency symbols and commas\n",
    "    if df['price'].dtype == object:\n",
    "        df['price'] = df['price'].replace('[\\₹,$,£,€,]', '', regex=True).astype(str).str.replace(',', '')\n",
    "        df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "    df['price'] = df['price'].fillna(df['price'].median())\n",
    "    \n",
    "    # Ensure rating is numeric\n",
    "    df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "    df['rating'] = df['rating'].fillna(df['rating'].median())\n",
    "    \n",
    "    # Fix reviews_count - ensure it's numeric\n",
    "    df['reviews_count'] = pd.to_numeric(df['reviews_count'], errors='coerce')\n",
    "    df['reviews_count'] = df['reviews_count'].fillna(0)\n",
    "    \n",
    "    # Clean and preprocess the title\n",
    "    df['processed_title'] = df['title'].apply(preprocess_text)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create a comprehensive content representation\n",
    "def create_content_representation(df):\n",
    "    # Create numerical features representation\n",
    "    def create_feature_soup(row):\n",
    "        features = []\n",
    "        \n",
    "        # Add prime status\n",
    "        prime_status = 'prime' if row.get('prime') == 1 else 'not_prime'\n",
    "        features.append(prime_status)\n",
    "        \n",
    "        # Add category information directly\n",
    "        if isinstance(row.get('category'), str):\n",
    "            category = row.get('category').lower().replace(' ', '_')\n",
    "            features.append(f\"category_{category}\")\n",
    "        \n",
    "        # Add price range as a feature\n",
    "        if row['price'] < 500:\n",
    "            price_range = 'budget_price'\n",
    "        elif row['price'] < 7500:\n",
    "            price_range = 'mid_price'\n",
    "        else:\n",
    "            price_range = 'premium_price'\n",
    "        features.append(price_range)\n",
    "        \n",
    "        # Add rating range as a feature\n",
    "        if row['rating'] >= 4.5:\n",
    "            rating_range = 'top_rated'\n",
    "        elif row['rating'] >= 4.0:\n",
    "            rating_range = 'highly_rated'\n",
    "        elif row['rating'] >= 3.0:\n",
    "            rating_range = 'average_rated'\n",
    "        else:\n",
    "            rating_range = 'low_rated'\n",
    "        features.append(rating_range)\n",
    "        \n",
    "        # Add discount range\n",
    "        if row['discount'] >= 30:\n",
    "            discount_range = 'high_discount'\n",
    "        elif row['discount'] >= 10:\n",
    "            discount_range = 'medium_discount'\n",
    "        else:\n",
    "            discount_range = 'low_discount'\n",
    "        features.append(discount_range)\n",
    "        \n",
    "        # Add popularity based on reviews count\n",
    "        if row['reviews_count'] > 1000:\n",
    "            popularity = 'very_popular'\n",
    "        elif row['reviews_count'] > 100:\n",
    "            popularity = 'popular'\n",
    "        else:\n",
    "            popularity = 'less_popular'\n",
    "        features.append(popularity)\n",
    "        \n",
    "        return ' '.join(features)\n",
    "    \n",
    "    # Apply feature extraction for numerical and categorical features\n",
    "    df['feature_soup'] = df.apply(create_feature_soup, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Extract important terms from title that are likely relevant for cameras\n",
    "def extract_camera_terms(title):\n",
    "    if not isinstance(title, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Camera-specific terms to emphasize\n",
    "    camera_terms = [\n",
    "        'dslr', 'mirrorless', 'canon', 'nikon', 'sony', 'fujifilm', 'olympus', 'panasonic',\n",
    "        'lens', 'mm', 'zoom', 'wide', 'angle', 'telephoto', 'macro', 'portrait',\n",
    "        'megapixel', 'mp', 'sensor', 'cmos', 'full-frame', 'full frame', 'aps-c',\n",
    "        '4k', 'hd', 'video', 'recording', 'stabilization', 'stabilized', 'optical',\n",
    "        'digital', 'slr', 'point-and-shoot', 'compact', 'action', 'gopro', 'waterproof',\n",
    "        'wifi', 'bluetooth', 'memory', 'card', 'battery', 'shutter', 'iso', 'flash'\n",
    "    ]\n",
    "    \n",
    "    # Convert title to lowercase\n",
    "    title_lower = title.lower()\n",
    "    \n",
    "    # Extract camera terms that appear in the title\n",
    "    found_terms = []\n",
    "    for term in camera_terms:\n",
    "        if term in title_lower:\n",
    "            found_terms.append(term)\n",
    "    \n",
    "    # Also extract model numbers (patterns like \"A7III\", \"5D Mark IV\", \"D850\", etc.)\n",
    "    model_patterns = [\n",
    "        r'\\b[a-z]+\\d+[a-z]*\\b',    # like A7III, D850, X100F\n",
    "        r'\\b\\d+[a-z]+\\b',          # like 5DS, 7D\n",
    "        r'\\bmark\\s+[ivx]+\\b',      # like Mark IV, Mark III\n",
    "    ]\n",
    "    \n",
    "    for pattern in model_patterns:\n",
    "        matches = re.findall(pattern, title_lower)\n",
    "        found_terms.extend(matches)\n",
    "    \n",
    "    return ' '.join(found_terms)\n",
    "\n",
    "# Build the recommendation model\n",
    "def build_recommendation_model(df):\n",
    "    # Check if we have the processed title column\n",
    "    if 'processed_title' not in df.columns:\n",
    "        df['processed_title'] = df['title'].apply(preprocess_text)\n",
    "    \n",
    "    # Extract camera-specific terms from titles\n",
    "    df['camera_terms'] = df['title'].apply(extract_camera_terms)\n",
    "    \n",
    "    # Create TF-IDF vectorizer for title text\n",
    "    title_tfidf = TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2)  # Include both unigrams and bigrams\n",
    "    )\n",
    "    title_tfidf_matrix = title_tfidf.fit_transform(df['processed_title'])\n",
    "    \n",
    "    # Create TF-IDF vectorizer for camera-specific terms\n",
    "    camera_tfidf = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    # Check if we have any camera terms extracted\n",
    "    if df['camera_terms'].str.strip().str.len().sum() > 0:\n",
    "        camera_tfidf_matrix = camera_tfidf.fit_transform(df['camera_terms'])\n",
    "        has_camera_terms = True\n",
    "    else:\n",
    "        # If no camera terms found, use a dummy matrix\n",
    "        camera_tfidf_matrix = title_tfidf_matrix.copy()\n",
    "        has_camera_terms = False\n",
    "    \n",
    "    # Create TF-IDF vectorizer for feature soup\n",
    "    feature_tfidf = TfidfVectorizer(stop_words='english')\n",
    "    feature_tfidf_matrix = feature_tfidf.fit_transform(df['feature_soup'])\n",
    "    \n",
    "    # Calculate similarity matrices\n",
    "    title_sim = cosine_similarity(title_tfidf_matrix, title_tfidf_matrix)\n",
    "    feature_sim = cosine_similarity(feature_tfidf_matrix, feature_tfidf_matrix)\n",
    "    \n",
    "    # If we have camera terms, include them in the combined similarity\n",
    "    if has_camera_terms:\n",
    "        camera_sim = cosine_similarity(camera_tfidf_matrix, camera_tfidf_matrix)\n",
    "        # Weight: 50% title, 30% camera-specific terms, 20% other features\n",
    "        combined_sim = 0.5 * title_sim + 0.3 * camera_sim + 0.2 * feature_sim\n",
    "    else:\n",
    "        # Without camera terms: 70% title, 30% other features\n",
    "        combined_sim = 0.7 * title_sim + 0.3 * feature_sim\n",
    "    \n",
    "    return combined_sim\n",
    "\n",
    "# Get recommendations function\n",
    "def get_recommendations(product_idx, cosine_sim, df, top_n=5):\n",
    "    \"\"\"\n",
    "    Get recommendations for a product based on its index\n",
    "    \n",
    "    Parameters:\n",
    "    product_idx (int): Index of the product in the dataframe\n",
    "    cosine_sim (numpy.ndarray): Cosine similarity matrix\n",
    "    df (pandas.DataFrame): DataFrame containing product information\n",
    "    top_n (int): Number of recommendations to return\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Recommended products with similarity scores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure index is within range\n",
    "        if product_idx < 0 or product_idx >= len(df):\n",
    "            print(f\"Product index {product_idx} is out of range (0-{len(df)-1}).\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        # Get similarity scores with other products\n",
    "        sim_scores = list(enumerate(cosine_sim[product_idx]))\n",
    "        \n",
    "        # Sort products based on similarity scores\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Get top N most similar products (excluding itself)\n",
    "        sim_scores = sim_scores[1:top_n+1]\n",
    "        \n",
    "        # Get product indices\n",
    "        product_indices = [i[0] for i in sim_scores]\n",
    "        \n",
    "        # Return recommended products with similarity scores\n",
    "        columns_to_include = ['title', 'price', 'rating', 'category', 'discount', 'reviews_count']\n",
    "        available_columns = [col for col in columns_to_include if col in df.columns]\n",
    "        \n",
    "        recommendations = df.iloc[product_indices][available_columns].copy()\n",
    "        recommendations['similarity_score'] = [score for _, score in sim_scores]\n",
    "        recommendations['product_index'] = product_indices  # Add index for reference\n",
    "        \n",
    "        return recommendations\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting recommendations: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Main function to run the entire recommendation pipeline\n",
    "def run_recommendation_system(df, sample_idx=None, top_n=5):\n",
    "    # Preprocess the data\n",
    "    print(\"Preprocessing data...\")\n",
    "    processed_df = preprocess_data(df)\n",
    "    \n",
    "    # Create content representation\n",
    "    print(\"Creating content representation...\")\n",
    "    content_df = create_content_representation(processed_df)\n",
    "    \n",
    "    # Build recommendation model\n",
    "    print(\"Building recommendation model...\")\n",
    "    combined_sim = build_recommendation_model(content_df)\n",
    "    \n",
    "    # If no sample index is provided, select a random product\n",
    "    if sample_idx is None:\n",
    "        sample_idx = np.random.randint(0, len(content_df))\n",
    "    \n",
    "    # Display the sample product details\n",
    "    sample_product = content_df.iloc[sample_idx]\n",
    "    \n",
    "    print(\"\\nExample Product (Index {}):\".format(sample_idx))\n",
    "    if 'title' in sample_product:\n",
    "        print(f\"Title: {sample_product['title']}\")\n",
    "    if 'price' in sample_product:\n",
    "        print(f\"Price: ${sample_product['price']:.2f}\")\n",
    "    if 'rating' in sample_product:\n",
    "        print(f\"Rating: {sample_product['rating']}\")\n",
    "    if 'category' in sample_product:\n",
    "        print(f\"Category: {sample_product['category']}\")\n",
    "    if 'discount' in sample_product:\n",
    "        print(f\"Discount: {sample_product['discount']}%\")\n",
    "    if 'reviews_count' in sample_product:\n",
    "        print(f\"Reviews Count: {sample_product['reviews_count']}\")\n",
    "    \n",
    "    # Get recommendations for the sample product\n",
    "    print(\"\\nGetting recommendations...\")\n",
    "    recommendations = get_recommendations(sample_idx, combined_sim, content_df, top_n=top_n)\n",
    "    \n",
    "    # Display recommendations\n",
    "    print(\"\\nTop {} Recommended Products:\".format(top_n))\n",
    "    for i, (_, recommendation) in enumerate(recommendations.iterrows(), 1):\n",
    "        print(f\"\\nRecommendation {i} (Index {recommendation['product_index']}):\")\n",
    "        \n",
    "        for col in recommendations.columns:\n",
    "            if col not in ['similarity_score', 'product_index']:\n",
    "                print(f\"{col.capitalize()}: {recommendation[col]}\")\n",
    "        \n",
    "        print(f\"Similarity Score: {recommendation['similarity_score']:.4f}\")\n",
    "    \n",
    "    # Visualize the recommendations similarity\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    similarity_scores = recommendations['similarity_score'].values\n",
    "    plt.bar(range(len(similarity_scores)), similarity_scores)\n",
    "    plt.xlabel('Recommendation')\n",
    "    plt.ylabel('Similarity Score')\n",
    "    plt.title(f'Similarity Scores for Products Similar to Product #{sample_idx}')\n",
    "    plt.xticks(range(len(similarity_scores)), [f'Rec {i+1}' for i in range(len(similarity_scores))])\n",
    "    plt.savefig('recommendation_similarity.png')\n",
    "    print(\"\\nRecommendation similarity visualization saved as 'recommendation_similarity.png'\")\n",
    "    \n",
    "    return recommendations, combined_sim\n",
    "\n",
    "# Function to search for products and get recommendations\n",
    "def search_and_recommend(df, query, top_n=5):\n",
    "    \"\"\"\n",
    "    Search for products matching a query and recommend similar products\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing product information\n",
    "    query (str): Search query (e.g., \"Canon camera\")\n",
    "    top_n (int): Number of recommendations to return\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (search_results, recommendations)\n",
    "    \"\"\"\n",
    "    # Preprocess the data if not already done\n",
    "    if 'processed_title' not in df.columns:\n",
    "        df = preprocess_data(df)\n",
    "        df = create_content_representation(df)\n",
    "    \n",
    "    # Preprocess the query\n",
    "    processed_query = preprocess_text(query)\n",
    "    \n",
    "    # Create a TF-IDF vectorizer for the search\n",
    "    search_tfidf = TfidfVectorizer(stop_words='english')\n",
    "    title_matrix = search_tfidf.fit_transform(df['processed_title'])\n",
    "    \n",
    "    # Convert query to vector\n",
    "    query_vector = search_tfidf.transform([processed_query])\n",
    "    \n",
    "    # Calculate similarity scores\n",
    "    similarity_scores = cosine_similarity(query_vector, title_matrix).flatten()\n",
    "    \n",
    "    # Get top search results\n",
    "    top_indices = similarity_scores.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    columns_to_include = ['title', 'price', 'rating', 'category', 'discount', 'reviews_count']\n",
    "    available_columns = [col for col in columns_to_include if col in df.columns]\n",
    "    \n",
    "    search_results = df.iloc[top_indices][available_columns].copy()\n",
    "    search_results['search_score'] = similarity_scores[top_indices]\n",
    "    \n",
    "    # If we found at least one result, get recommendations for the top match\n",
    "    if len(top_indices) > 0:\n",
    "        # Build recommendation model\n",
    "        combined_sim = build_recommendation_model(df)\n",
    "        \n",
    "        # Get recommendations for the top search result\n",
    "        recommendations = get_recommendations(top_indices[0], combined_sim, df, top_n)\n",
    "        return search_results, recommendations\n",
    "    else:\n",
    "        return search_results, pd.DataFrame()\n",
    "\n",
    "# Example code to load data and run the recommendation system\n",
    "# \"\"\"\n",
    "# # Assuming you have a CSV file with your data\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# # Run the recommendation system\n",
    "recommendations, similarity_matrix = run_recommendation_system(df)\n",
    "\n",
    "# # Or search for camera products and get recommendations\n",
    "search_results, recommendations = search_and_recommend(df, \"canon dslr camera\")\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLLABORATIVE FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Product (Index 588):\n",
      "Title: soundcore by Anker Pyro Mini Portable and Compact 6W Bluetooth Speaker with Loud and Strong bass, 10 Hrs Playtime, 57mm Driver, Bluetooth 5.3 Connectivity- Black\n",
      "Price: 599.0\n",
      "Rating: 4.0\n",
      "Category: headphones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vinay Venkatachalam\\AppData\\Local\\Temp\\ipykernel_21852\\2512665930.py:135: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  basket_binary = basket.applymap(lambda x: 1 if x > 0 else 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similar Products:\n",
      "\n",
      "1. soundcore by Anker H30i Wireless On-Ear Headphones, Foldable Design, Pure Bass, 70H Playtime, Bluetooth 5.3, Lightweight and Comfortable, App Connectivity, Multipoint Connection (Black)\n",
      "   Price: 2999.0\n",
      "   Rating: 4.2\n",
      "   Category: headphones\n",
      "   Similarity: 0.3820\n",
      "\n",
      "2. soundcore by Anker H30i Wireless On-Ear Headphones, Foldable Design, Pure Bass, 70H Playtime, Bluetooth 5.3, Lightweight and Comfortable, App Connectivity, Multipoint Connection (Black)\n",
      "   Price: 2999.0\n",
      "   Rating: 4.2\n",
      "   Category: headphones\n",
      "   Similarity: 0.3661\n",
      "\n",
      "3. Amkette Optimus BT 4 in 1 Wireless Keyboard 2.4 GHz & Bluetooth 5.0 Connectivity with 3 Bluetooth and 1 USB Device, Compact Bluetooth Keyboard, On/Off Switch, Silent Keys, Shortcut Multimedia Keys\n",
      "   Price: 899.0\n",
      "   Rating: 4.0\n",
      "   Category: keyboards\n",
      "   Similarity: 0.3429\n",
      "\n",
      "Frequently Bought Together:\n",
      "\n",
      "1. Sponsored Ad - Elevea 𝟏𝟓 𝐘𝐞𝐚𝐫𝐬 𝐖𝐚𝐫𝐫𝐚𝐧𝐭𝐲 4K HD 1080 Action Camera, Dual 2 Inch LCD Screen 16 MP, Image Sensor 170 Wide-Angle Lens Sports Action Camera for Underwater Adventure.\n",
      "   Price: 1999.0\n",
      "   Rating: 5.0\n",
      "   Category: cameras\n",
      "   Relevance: 2.0000\n",
      "\n",
      "2. Sponsored Ad - Drumstone Summer 𝐖𝐢𝐭𝐡 𝟏𝟓 𝐘𝐄𝐀𝐑𝐒 𝐖𝐀𝐑𝐑𝐀𝐍𝐓𝐘 New Launch 4K Ultra HD WiFi Action Camera Wireless Water Resistant Sports Action Camera Wide-Angle Lens with 2 Inch Display CMOS (16MP)-\n",
      "   Price: 1999.0\n",
      "   Rating: 5.0\n",
      "   Category: cameras\n",
      "   Relevance: 2.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vinay Venkatachalam\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define category-specific complementary relationships\n",
    "CATEGORY_RELATIONSHIPS = {\n",
    "    'laptops': ['keyboards', 'headphones'],\n",
    "    'phones': ['mobile back covers', 'headphones'],\n",
    "    'cameras': ['headphones'],\n",
    "    'tv': ['headphones'],\n",
    "    'printers': ['laptops'],\n",
    "    'keyboards': ['laptops'],\n",
    "    'mobile back covers': ['phones'],\n",
    "    'headphones': ['phones', 'laptops', 'tv', 'cameras']\n",
    "}\n",
    "\n",
    "# Function to categorize products\n",
    "def categorize_products(df):\n",
    "    \"\"\"\n",
    "    Add category information if not already present, based on product title\n",
    "    \"\"\"\n",
    "    if 'category' in df.columns:\n",
    "        return df\n",
    "    \n",
    "    category_keywords = {\n",
    "        'laptops': ['laptop', 'notebook', 'macbook', 'thinkpad', 'ideapad', 'ultrabook'],\n",
    "        'keyboards': ['keyboard', 'mechanical keyboard', 'gaming keyboard', 'wireless keyboard'],\n",
    "        'headphones': ['headphone', 'earphone', 'earbud', 'headset', 'earpiece'],\n",
    "        'phones': ['phone', 'smartphone', 'iphone', 'android', 'mobile phone', 'cell phone'],\n",
    "        'mobile back covers': ['phone case', 'back cover', 'phone cover', 'mobile case', 'phone shell'],\n",
    "        'cameras': ['camera', 'dslr', 'mirrorless', 'digital camera', 'action camera', 'point and shoot'],\n",
    "        'printers': ['printer', 'laser printer', 'inkjet', 'all-in-one printer'],\n",
    "        'tv': ['tv', 'television', 'smart tv', 'led tv', 'oled', 'qled', 'lcd tv']\n",
    "    }\n",
    "    \n",
    "    def detect_category(title):\n",
    "        if not isinstance(title, str):\n",
    "            return 'unknown'\n",
    "            \n",
    "        title_lower = title.lower()\n",
    "        for category, keywords in category_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in title_lower:\n",
    "                    return category\n",
    "        return 'unknown'\n",
    "    \n",
    "    df['category'] = df['title'].apply(detect_category)\n",
    "    return df\n",
    "\n",
    "# Function to simulate transaction data based on your specific product categories\n",
    "def simulate_category_based_transactions(df, num_transactions=1000):\n",
    "    \"\"\"\n",
    "    Simulate transaction data based on predefined category relationships\n",
    "    \"\"\"\n",
    "    # Ensure we have category information\n",
    "    df = categorize_products(df)\n",
    "    \n",
    "    # Create category-to-products mapping\n",
    "    category_to_products = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        category = row.get('category', 'unknown')\n",
    "        if category not in category_to_products:\n",
    "            category_to_products[category] = []\n",
    "        category_to_products[category].append(idx)\n",
    "    \n",
    "    # Simulate transactions\n",
    "    transactions = []\n",
    "    for i in range(num_transactions):\n",
    "        transaction_id = f'T{i+1}'\n",
    "        \n",
    "        # Select a random primary category\n",
    "        primary_category = np.random.choice(list(CATEGORY_RELATIONSHIPS.keys()))\n",
    "        \n",
    "        # Skip if no products in this category\n",
    "        if primary_category not in category_to_products or not category_to_products[primary_category]:\n",
    "            continue\n",
    "            \n",
    "        # Select a primary product\n",
    "        primary_product = np.random.choice(category_to_products[primary_category])\n",
    "        transactions.append({\n",
    "            'transaction_id': transaction_id,\n",
    "            'product_id': primary_product,\n",
    "            'quantity': 1\n",
    "        })\n",
    "        \n",
    "        # Add complementary products based on category relationships\n",
    "        if primary_category in CATEGORY_RELATIONSHIPS:\n",
    "            for comp_category in CATEGORY_RELATIONSHIPS[primary_category]:\n",
    "                # Only add if we have products in this category and with 70% probability\n",
    "                if comp_category in category_to_products and category_to_products[comp_category] and np.random.random() < 0.7:\n",
    "                    comp_product = np.random.choice(category_to_products[comp_category])\n",
    "                    transactions.append({\n",
    "                        'transaction_id': transaction_id,\n",
    "                        'product_id': comp_product,\n",
    "                        'quantity': 1\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(transactions)\n",
    "\n",
    "# Function to build complementary product model with category awareness\n",
    "def build_category_aware_complementary_model(df, transaction_data=None):\n",
    "    \"\"\"\n",
    "    Build a model for complementary product recommendations with category awareness\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame with product information\n",
    "    transaction_data (pandas.DataFrame, optional): Transaction data if available\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary mapping product IDs to recommended complementary product IDs\n",
    "    \"\"\"\n",
    "    # Ensure we have category information\n",
    "    df = categorize_products(df)\n",
    "    \n",
    "    # If no transaction data provided, simulate it\n",
    "    if transaction_data is None:\n",
    "        transaction_data = simulate_category_based_transactions(df)\n",
    "    \n",
    "    # Check if we have enough transaction data\n",
    "    if len(transaction_data) < 10:\n",
    "        print(\"Warning: Not enough transaction data for reliable association rules.\")\n",
    "        # Fall back to category-based recommendations\n",
    "        return build_fallback_category_model(df)\n",
    "    \n",
    "    try:\n",
    "        # Create a one-hot encoded matrix for products in transactions\n",
    "        basket = (transaction_data\n",
    "                 .groupby(['transaction_id', 'product_id'])['quantity']\n",
    "                 .sum().unstack().reset_index().fillna(0)\n",
    "                 .set_index('transaction_id'))\n",
    "        \n",
    "        # Convert to binary (purchased or not)\n",
    "        basket_binary = basket.applymap(lambda x: 1 if x > 0 else 0)\n",
    "        \n",
    "        # Run the Apriori algorithm to find frequent itemsets\n",
    "        frequent_itemsets = apriori(basket_binary, min_support=0.01, use_colnames=True)\n",
    "        \n",
    "        # Generate association rules if we have frequent itemsets\n",
    "        if len(frequent_itemsets) > 0:\n",
    "            rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "            \n",
    "            # Sort by lift\n",
    "            rules = rules.sort_values('lift', ascending=False)\n",
    "            \n",
    "            # Create a lookup dictionary for complementary products\n",
    "            complementary_dict = {}\n",
    "            for _, row in rules.iterrows():\n",
    "                antecedent = frozenset(row['antecedents'])\n",
    "                consequent = frozenset(row['consequents'])\n",
    "                \n",
    "                # Only consider rules with single antecedent and consequent\n",
    "                if len(antecedent) == 1 and len(consequent) == 1:\n",
    "                    antecedent_item = list(antecedent)[0]\n",
    "                    consequent_item = list(consequent)[0]\n",
    "                    \n",
    "                    if antecedent_item not in complementary_dict:\n",
    "                        complementary_dict[antecedent_item] = []\n",
    "                    \n",
    "                    complementary_dict[antecedent_item].append({\n",
    "                        'product_id': consequent_item,\n",
    "                        'lift': row['lift'],\n",
    "                        'confidence': row['confidence']\n",
    "                    })\n",
    "            \n",
    "            return complementary_dict\n",
    "        else:\n",
    "            print(\"No frequent itemsets found. Using fallback category model.\")\n",
    "            return build_fallback_category_model(df)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error building association rules: {e}\")\n",
    "        return build_fallback_category_model(df)\n",
    "\n",
    "# Fallback method using predefined category relationships\n",
    "def build_fallback_category_model(df):\n",
    "    \"\"\"\n",
    "    Build a fallback complementary product model based on category relationships\n",
    "    when transaction data is insufficient\n",
    "    \"\"\"\n",
    "    complementary_dict = {}\n",
    "    \n",
    "    # For each product, find complementary products from related categories\n",
    "    for idx, row in df.iterrows():\n",
    "        product_category = row.get('category', 'unknown')\n",
    "        \n",
    "        # Skip if unknown category or no complementary categories defined\n",
    "        if product_category == 'unknown' or product_category not in CATEGORY_RELATIONSHIPS:\n",
    "            continue\n",
    "        \n",
    "        complementary_dict[idx] = []\n",
    "        \n",
    "        # Find products from complementary categories\n",
    "        for comp_category in CATEGORY_RELATIONSHIPS[product_category]:\n",
    "            comp_products = df[df['category'] == comp_category]\n",
    "            \n",
    "            # Skip if no products in this category\n",
    "            if len(comp_products) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Add top 3 products from each complementary category (based on rating or reviews)\n",
    "            if 'rating' in comp_products.columns:\n",
    "                top_products = comp_products.sort_values('rating', ascending=False).head(3)\n",
    "            elif 'reviews_count' in comp_products.columns:\n",
    "                top_products = comp_products.sort_values('reviews_count', ascending=False).head(3)\n",
    "            else:\n",
    "                top_products = comp_products.head(3)\n",
    "            \n",
    "            for comp_idx, comp_row in top_products.iterrows():\n",
    "                # Don't recommend the same product\n",
    "                if comp_idx == idx:\n",
    "                    continue\n",
    "                    \n",
    "                complementary_dict[idx].append({\n",
    "                    'product_id': comp_idx,\n",
    "                    'lift': 2.0,  # Default lift score\n",
    "                    'confidence': 0.7  # Default confidence\n",
    "                })\n",
    "    \n",
    "    return complementary_dict\n",
    "\n",
    "# Function to get complementary recommendations\n",
    "def get_category_complementary_recommendations(product_idx, df, complementary_dict=None, top_n=3):\n",
    "    \"\"\"\n",
    "    Get complementary product recommendations with category awareness\n",
    "    \n",
    "    Parameters:\n",
    "    product_idx (int): Index of the product\n",
    "    df (pandas.DataFrame): DataFrame with product information\n",
    "    complementary_dict (dict, optional): Pre-built complementary product dictionary\n",
    "    top_n (int): Number of recommendations to return\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Complementary product recommendations\n",
    "    \"\"\"\n",
    "    # Ensure we have category information\n",
    "    df = categorize_products(df)\n",
    "    \n",
    "    # If no complementary dictionary provided, build it\n",
    "    if complementary_dict is None:\n",
    "        complementary_dict = build_category_aware_complementary_model(df)\n",
    "    \n",
    "    # If product has complementary products in the dictionary\n",
    "    if product_idx in complementary_dict and complementary_dict[product_idx]:\n",
    "        # Get complementary products sorted by lift\n",
    "        comp_products = sorted(complementary_dict[product_idx], \n",
    "                              key=lambda x: x['lift'], \n",
    "                              reverse=True)[:top_n]\n",
    "        \n",
    "        # Get product indices\n",
    "        product_indices = [item['product_id'] for item in comp_products]\n",
    "        \n",
    "    else:\n",
    "        # Fallback: Use category relationships directly\n",
    "        product_category = df.loc[product_idx, 'category'] if product_idx in df.index else 'unknown'\n",
    "        \n",
    "        if product_category in CATEGORY_RELATIONSHIPS:\n",
    "            complementary_categories = CATEGORY_RELATIONSHIPS[product_category]\n",
    "            \n",
    "            # Find products from complementary categories\n",
    "            comp_products_df = df[df['category'].isin(complementary_categories)]\n",
    "            \n",
    "            # Sort by rating or reviews if available\n",
    "            if 'rating' in comp_products_df.columns:\n",
    "                comp_products_df = comp_products_df.sort_values('rating', ascending=False)\n",
    "            elif 'reviews_count' in comp_products_df.columns:\n",
    "                comp_products_df = comp_products_df.sort_values('reviews_count', ascending=False)\n",
    "            \n",
    "            # Get top products\n",
    "            product_indices = comp_products_df.head(top_n).index.tolist()\n",
    "            \n",
    "            # Create fake lift and confidence scores\n",
    "            comp_products = [{'product_id': pid, 'lift': 2.0, 'confidence': 0.7} for pid in product_indices]\n",
    "        else:\n",
    "            # No category relationship found\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    # Return recommended products\n",
    "    if not product_indices:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    columns_to_include = ['title', 'price', 'rating', 'category', 'discount', 'reviews_count']\n",
    "    available_columns = [col for col in columns_to_include if col in df.columns]\n",
    "    \n",
    "    recommendations = df.loc[product_indices][available_columns].copy()\n",
    "    recommendations['lift_score'] = [item['lift'] for item in comp_products]\n",
    "    recommendations['confidence'] = [item['confidence'] for item in comp_products]\n",
    "    recommendations['product_index'] = product_indices\n",
    "    recommendations['recommendation_type'] = 'complementary'\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Main function to run enhanced recommendation system\n",
    "def run_category_enhanced_recommendations(df, product_idx=None, similar_count=3, complementary_count=2):\n",
    "    \"\"\"\n",
    "    Get recommendations with both similarity-based and category-based complementary products\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame with product information\n",
    "    product_idx (int, optional): Product index to recommend for. If None, selects a random product.\n",
    "    similar_count (int): Number of similar products to recommend\n",
    "    complementary_count (int): Number of complementary products to recommend\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (similar_recommendations, complementary_recommendations)\n",
    "    \"\"\"\n",
    "    # Preprocess data if needed (assuming preprocess_data and create_content_representation\n",
    "    # functions are defined elsewhere in your code)\n",
    "    if 'processed_title' not in df.columns and 'preprocess_data' in globals():\n",
    "        df = preprocess_data(df)\n",
    "        df = create_content_representation(df)\n",
    "    \n",
    "    # Ensure we have category information\n",
    "    df = categorize_products(df)\n",
    "    \n",
    "    # Select a random product if none specified\n",
    "    if product_idx is None or product_idx not in df.index:\n",
    "        product_idx = np.random.choice(df.index)\n",
    "    \n",
    "    # Display selected product\n",
    "    product = df.loc[product_idx]\n",
    "    print(f\"\\nSelected Product (Index {product_idx}):\")\n",
    "    for col in ['title', 'price', 'rating', 'category']:\n",
    "        if col in product:\n",
    "            print(f\"{col.capitalize()}: {product[col]}\")\n",
    "    \n",
    "    # Get similar product recommendations\n",
    "    similar_recs = pd.DataFrame()\n",
    "    if 'build_recommendation_model' in globals():\n",
    "        # Build similarity matrix if not available\n",
    "        similarity_matrix = build_recommendation_model(df)\n",
    "        similar_recs = get_recommendations(product_idx, similarity_matrix, df, top_n=similar_count)\n",
    "    else:\n",
    "        # Fallback method if similarity functions not available\n",
    "        print(\"Similar product recommendation functions not available. Implementing basic similarity.\")\n",
    "        similar_recs = get_fallback_similar_recommendations(product_idx, df, top_n=similar_count)\n",
    "    \n",
    "    # Get complementary product recommendations\n",
    "    complementary_dict = build_category_aware_complementary_model(df)\n",
    "    comp_recs = get_category_complementary_recommendations(\n",
    "        product_idx, df, complementary_dict, top_n=complementary_count\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nSimilar Products:\")\n",
    "    if not similar_recs.empty:\n",
    "        for i, (_, rec) in enumerate(similar_recs.iterrows(), 1):\n",
    "            print(f\"\\n{i}. {rec.get('title', f'Product {rec.name}')}\")\n",
    "            for col in ['price', 'rating', 'category']:\n",
    "                if col in rec:\n",
    "                    print(f\"   {col.capitalize()}: {rec[col]}\")\n",
    "            if 'similarity_score' in rec:\n",
    "                print(f\"   Similarity: {rec['similarity_score']:.4f}\")\n",
    "    else:\n",
    "        print(\"No similar products found\")\n",
    "    \n",
    "    print(\"\\nFrequently Bought Together:\")\n",
    "    if not comp_recs.empty:\n",
    "        for i, (_, rec) in enumerate(comp_recs.iterrows(), 1):\n",
    "            print(f\"\\n{i}. {rec.get('title', f'Product {rec.name}')}\")\n",
    "            for col in ['price', 'rating', 'category']:\n",
    "                if col in rec:\n",
    "                    print(f\"   {col.capitalize()}: {rec[col]}\")\n",
    "            if 'lift_score' in rec:\n",
    "                print(f\"   Relevance: {rec['lift_score']:.4f}\")\n",
    "    else:\n",
    "        print(\"No complementary products found\")\n",
    "    \n",
    "    return similar_recs, comp_recs\n",
    "\n",
    "# Fallback similar product recommendation if your original functions are not available\n",
    "def get_fallback_similar_recommendations(product_idx, df, top_n=3):\n",
    "    \"\"\"\n",
    "    Fallback method to find similar products if main similarity functions are not available\n",
    "    \"\"\"\n",
    "    # Ensure product_idx is in the DataFrame\n",
    "    if product_idx not in df.index:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get the product category\n",
    "    product = df.loc[product_idx]\n",
    "    product_category = product.get('category', 'unknown')\n",
    "    \n",
    "    # Find products in the same category\n",
    "    category_products = df[df['category'] == product_category]\n",
    "    \n",
    "    # Exclude the query product\n",
    "    category_products = category_products[category_products.index != product_idx]\n",
    "    \n",
    "    # If we have TF-IDF capability, use it for title similarity\n",
    "    if 'TfidfVectorizer' in globals():\n",
    "        # Create a basic TF-IDF for titles\n",
    "        if 'title' in df.columns:\n",
    "            tfidf = TfidfVectorizer(stop_words='english')\n",
    "            title_matrix = tfidf.fit_transform(df['title'].fillna('').astype(str))\n",
    "            \n",
    "            # Get similarity scores\n",
    "            product_vector = title_matrix[df.index.get_loc(product_idx)]\n",
    "            similarity_scores = cosine_similarity(product_vector, title_matrix).flatten()\n",
    "            \n",
    "            # Sort by similarity\n",
    "            similar_indices = similarity_scores.argsort()[::-1][1:top_n+1]  # Exclude itself\n",
    "            similar_products = df.iloc[similar_indices].copy()\n",
    "            similar_products['similarity_score'] = similarity_scores[similar_indices]\n",
    "            \n",
    "            return similar_products\n",
    "    \n",
    "    # Otherwise, sort by rating or reviews if available\n",
    "    if len(category_products) >= top_n:\n",
    "        if 'rating' in category_products.columns:\n",
    "            similar_products = category_products.sort_values('rating', ascending=False).head(top_n)\n",
    "        elif 'reviews_count' in category_products.columns:\n",
    "            similar_products = category_products.sort_values('reviews_count', ascending=False).head(top_n)\n",
    "        else:\n",
    "            similar_products = category_products.head(top_n)\n",
    "        \n",
    "        # Add a dummy similarity score\n",
    "        similar_products = similar_products.copy()\n",
    "        similar_products['similarity_score'] = 0.8  # Default similarity\n",
    "        \n",
    "        return similar_products\n",
    "    \n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Example usage\n",
    "similar_recs, comp_recs = run_category_enhanced_recommendations(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUAL SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import hashlib  # For duplicate detection\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"/content/merged_data.csv\")\n",
    "\n",
    "# Create a directory to save images\n",
    "image_dir = \"downloaded_images\"\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "# Track downloaded ASINs to avoid duplicates\n",
    "downloaded_asins = set()\n",
    "file_hashes = {}  # To track duplicate image content\n",
    "\n",
    "# Function to download an image\n",
    "def download_image(image_url, save_path):\n",
    "    try:\n",
    "        response = requests.get(image_url, timeout=5)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Calculate hash of image content to detect duplicates\n",
    "        content = response.content\n",
    "        image_hash = hashlib.md5(content).hexdigest()\n",
    "        \n",
    "        # Check if we've seen this exact image before\n",
    "        if image_hash in file_hashes:\n",
    "            print(f\"Duplicate image content detected: {save_path} matches {file_hashes[image_hash]}\")\n",
    "            return False\n",
    "        \n",
    "        # Save the new image\n",
    "        with open(save_path, \"wb\") as file:\n",
    "            file.write(content)\n",
    "        \n",
    "        # Record this hash\n",
    "        file_hashes[image_hash] = save_path\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {image_url}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Loop through image URLs and download images\n",
    "successful_downloads = 0\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Downloading Images\"):\n",
    "    image_url = row[\"image_url\"]\n",
    "    \n",
    "    # Check if we have an ASIN column, otherwise skip\n",
    "    if \"asin\" not in row or pd.isna(row[\"asin\"]):\n",
    "        print(f\"Row {idx} missing ASIN, skipping\")\n",
    "        continue\n",
    "    \n",
    "    asin = row[\"asin\"]\n",
    "    \n",
    "    # Skip if we've already downloaded this ASIN\n",
    "    if asin in downloaded_asins:\n",
    "        print(f\"Skipping duplicate ASIN: {asin}\")\n",
    "        continue\n",
    "    \n",
    "    # Generate filename with ASIN\n",
    "    image_name = f\"{asin}.jpg\"\n",
    "    save_path = os.path.join(image_dir, image_name)\n",
    "    \n",
    "    if pd.notna(image_url):  # Check if URL is not NaN\n",
    "        if download_image(image_url, save_path):\n",
    "            downloaded_asins.add(asin)  # Mark this ASIN as downloaded\n",
    "            successful_downloads += 1\n",
    "\n",
    "print(f\"✅ Image download complete! {successful_downloads} unique images saved in 'downloaded_images' folder.\")\n",
    "print(f\"Prevented {len(df) - successful_downloads} duplicate or failed downloads.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import re\n",
    "\n",
    "class ProductVisualSearch:\n",
    "    def __init__(self, images_directory, product_data_path):\n",
    "        \"\"\"\n",
    "        Initialize the visual search system\n",
    "        \n",
    "        Args:\n",
    "            images_directory: Path to directory containing product images\n",
    "            product_data_path: Path to CSV file containing product metadata\n",
    "        \"\"\"\n",
    "        self.images_directory = images_directory\n",
    "        \n",
    "        # Load product metadata\n",
    "        self.product_data = pd.read_csv(product_data_path)\n",
    "        print(f\"Loaded product data with {len(self.product_data)} entries\")\n",
    "        \n",
    "        # Load pre-trained ResNet50 model without the top classification layer\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "        self.model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "        \n",
    "        # Set parameters\n",
    "        self.img_size = (224, 224)  # ResNet50 expected input size\n",
    "        \n",
    "        # Storage for image features, paths, and ASINs\n",
    "        self.features = []\n",
    "        self.image_paths = []\n",
    "        self.asins = []\n",
    "        \n",
    "        # Scan and index all images in the directory\n",
    "        self._index_images()\n",
    "    \n",
    "    def _extract_asin(self, filename):\n",
    "        \"\"\"Extract ASIN from filename\"\"\"\n",
    "        # Assuming filename format is ASIN.jpg (e.g., B0DQXGCPFJ.jpg)\n",
    "        asin = os.path.splitext(filename)[0]\n",
    "        # Verify it looks like an ASIN (typically 10 characters, alphanumeric)\n",
    "        if re.match(r'^[A-Z0-9]{10}$', asin):\n",
    "            return asin\n",
    "        return None\n",
    "    \n",
    "    def _index_images(self):\n",
    "        \"\"\"Scan the images directory and extract features from all images\"\"\"\n",
    "        print(f\"Indexing images from {self.images_directory}...\")\n",
    "        \n",
    "        valid_extensions = ('.jpg', '.jpeg', '.png')\n",
    "        count = 0\n",
    "        \n",
    "        for filename in os.listdir(self.images_directory):\n",
    "            if filename.lower().endswith(valid_extensions):\n",
    "                img_path = os.path.join(self.images_directory, filename)\n",
    "                \n",
    "                # Extract ASIN from filename\n",
    "                asin = self._extract_asin(filename)\n",
    "                if not asin:\n",
    "                    print(f\"Skipping {filename}: Could not extract valid ASIN\")\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Extract features\n",
    "                    feature = self._extract_features(img_path)\n",
    "                    \n",
    "                    # Store feature, path, and ASIN\n",
    "                    self.features.append(feature)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.asins.append(asin)\n",
    "                    \n",
    "                    count += 1\n",
    "                    if count % 10 == 0:\n",
    "                        print(f\"Processed {count} images\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {filename}: {e}\")\n",
    "        \n",
    "        # Convert features list to numpy array for faster processing\n",
    "        self.features = np.array(self.features)\n",
    "        print(f\"Indexed {len(self.features)} images successfully\")\n",
    "    \n",
    "    def _extract_features(self, img_path):\n",
    "        \"\"\"\n",
    "        Extract features from a single image using the pre-trained model\n",
    "        \n",
    "        Args:\n",
    "            img_path: Path to the image file\n",
    "            \n",
    "        Returns:\n",
    "            Feature vector for the image\n",
    "        \"\"\"\n",
    "        # Load and preprocess image\n",
    "        img = image.load_img(img_path, target_size=self.img_size)\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        \n",
    "        # Extract features - with ResNet50 and avg pooling, features are already flattened\n",
    "        features = self.model.predict(img_array, verbose=0)[0]\n",
    "        \n",
    "        # Normalize the features\n",
    "        features_normalized = features / np.linalg.norm(features)\n",
    "        \n",
    "        return features_normalized\n",
    "    \n",
    "    def get_product_info(self, asin):\n",
    "        \"\"\"Get product metadata for a given ASIN\"\"\"\n",
    "        product = self.product_data[self.product_data['asin'] == asin]\n",
    "        if len(product) == 0:\n",
    "            return {\n",
    "                'title': f\"Product {asin}\",\n",
    "                'price': \"N/A\",\n",
    "                'rating': \"N/A\",\n",
    "                'category': \"N/A\",\n",
    "                'asin': asin\n",
    "            }\n",
    "        \n",
    "        # Return first matching product\n",
    "        product = product.iloc[0]\n",
    "        return {\n",
    "            'title': product.get('title', f\"Product {asin}\"),\n",
    "            'price': product.get('price', \"N/A\"),\n",
    "            'rating': product.get('rating', \"N/A\"),\n",
    "            'category': product.get('category', \"N/A\"),\n",
    "            'asin': asin\n",
    "        }\n",
    "    \n",
    "    def search(self, query_img_path, top_k=5):\n",
    "        \"\"\"\n",
    "        Search for similar images to the query image\n",
    "        \n",
    "        Args:\n",
    "            query_img_path: Path to the query image\n",
    "            top_k: Number of top results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of (image_path, asin, product_info, similarity_score) tuples for top matches\n",
    "        \"\"\"\n",
    "        # Extract features from query image\n",
    "        query_features = self._extract_features(query_img_path)\n",
    "        \n",
    "        # Calculate similarity scores\n",
    "        similarities = cosine_similarity(query_features.reshape(1, -1), self.features)\n",
    "        similarities = similarities[0]\n",
    "        \n",
    "        # Get indices of top-k most similar images\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        # Create result list with image paths, ASINs, product info, and similarity scores\n",
    "        results = []\n",
    "        for i in top_indices:\n",
    "            asin = self.asins[i]\n",
    "            product_info = self.get_product_info(asin)\n",
    "            results.append((self.image_paths[i], asin, product_info, similarities[i]))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def visualize_results(self, query_img_path, results):\n",
    "        \"\"\"\n",
    "        Visualize search results with product information\n",
    "        \n",
    "        Args:\n",
    "            query_img_path: Path to the query image\n",
    "            results: List of (image_path, asin, product_info, similarity_score) tuples\n",
    "        \"\"\"\n",
    "        n_results = len(results)\n",
    "        plt.figure(figsize=(18, 4 + n_results * 4))\n",
    "        \n",
    "        # Extract ASIN from query image if available\n",
    "        query_asin = self._extract_asin(os.path.basename(query_img_path))\n",
    "        query_info = None\n",
    "        if query_asin:\n",
    "            query_info = self.get_product_info(query_asin)\n",
    "        \n",
    "        # Display query image with product info if available\n",
    "        plt.subplot(n_results + 1, 1, 1)\n",
    "        query_img = Image.open(query_img_path)\n",
    "        plt.imshow(query_img)\n",
    "        \n",
    "        if query_info:\n",
    "            title = f\"Query: {query_info['title'][:50]}...\" if len(query_info['title']) > 50 else f\"Query: {query_info['title']}\"\n",
    "            subtitle = f\"ASIN: {query_asin} | Price: {query_info['price']} | Rating: {query_info['rating']} | Category: {query_info['category']}\"\n",
    "        else:\n",
    "            title = \"Query Image\"\n",
    "            subtitle = os.path.basename(query_img_path)\n",
    "            \n",
    "        plt.title(title, fontsize=14)\n",
    "        plt.xlabel(subtitle, fontsize=10)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        # Display result images with product info\n",
    "        for i, (img_path, asin, product_info, score) in enumerate(results):\n",
    "            plt.subplot(n_results + 1, 1, i + 2)\n",
    "            result_img = Image.open(img_path)\n",
    "            plt.imshow(result_img)\n",
    "            \n",
    "            title = f\"{i+1}. {product_info['title'][:50]}...\" if len(product_info['title']) > 50 else f\"{i+1}. {product_info['title']}\"\n",
    "            subtitle = f\"ASIN: {asin} | Price: {product_info['price']} | Rating: {product_info['rating']} | Similarity: {score:.4f}\"\n",
    "            \n",
    "            plt.title(title, fontsize=12)\n",
    "            plt.xlabel(subtitle, fontsize=10)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def print_results(self, results):\n",
    "        \"\"\"\n",
    "        Print detailed search results\n",
    "        \n",
    "        Args:\n",
    "            results: List of (image_path, asin, product_info, similarity_score) tuples\n",
    "        \"\"\"\n",
    "        print(\"\\n===== SIMILAR PRODUCTS =====\")\n",
    "        for i, (img_path, asin, product_info, score) in enumerate(results):\n",
    "            print(f\"\\n{i+1}. ASIN: {asin} (Similarity: {score:.4f})\")\n",
    "            print(f\"   Title: {product_info['title']}\")\n",
    "            print(f\"   Price: {product_info['price']}\")\n",
    "            print(f\"   Rating: {product_info['rating']}\")\n",
    "            print(f\"   Category: {product_info['category']}\")\n",
    "            print(f\"   Image: {os.path.basename(img_path)}\")\n",
    "            print(\"   \" + \"-\"*50)\n",
    "\n",
    "    def save_model(self, save_directory):\n",
    "        \"\"\"\n",
    "        Save the trained model and indexed features\n",
    "        \n",
    "        Args:\n",
    "            save_directory: Directory path to save the model and features\n",
    "        \"\"\"\n",
    "        os.makedirs(save_directory, exist_ok=True)\n",
    "        \n",
    "        # Save the feature extraction model\n",
    "        model_path = os.path.join(save_directory, \"resnet_feature_extractor.h5\")\n",
    "        self.model.save(model_path)\n",
    "        print(f\"Model saved to {model_path}\")\n",
    "        \n",
    "        # Save the indexed features, image paths, and ASINs\n",
    "        features_data = {\n",
    "            'features': self.features,\n",
    "            'image_paths': self.image_paths,\n",
    "            'asins': self.asins\n",
    "        }\n",
    "        \n",
    "        features_path = os.path.join(save_directory, \"indexed_features.pkl\")\n",
    "        with open(features_path, 'wb') as f:\n",
    "            pickle.dump(features_data, f)\n",
    "        print(f\"Indexed features saved to {features_path}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls, save_directory, product_data_path):\n",
    "        \"\"\"\n",
    "        Load a previously saved model and indexed features\n",
    "        \n",
    "        Args:\n",
    "            save_directory: Directory path where model and features were saved\n",
    "            product_data_path: Path to CSV file containing product metadata\n",
    "            \n",
    "        Returns:\n",
    "            ProductVisualSearch instance with loaded model and features\n",
    "        \"\"\"\n",
    "        # Create an instance without initializing\n",
    "        instance = cls.__new__(cls)\n",
    "        \n",
    "        # Load product data\n",
    "        instance.product_data = pd.read_csv(product_data_path)\n",
    "        instance.images_directory = None  # Not needed for loading\n",
    "        instance.img_size = (224, 224)  # ResNet50 expected input size\n",
    "        \n",
    "        # Load the model\n",
    "        model_path = os.path.join(save_directory, \"resnet_feature_extractor.h5\")\n",
    "        instance.model = tf.keras.models.load_model(model_path)\n",
    "        print(f\"Model loaded from {model_path}\")\n",
    "        \n",
    "        # Load the indexed features\n",
    "        features_path = os.path.join(save_directory, \"indexed_features.pkl\")\n",
    "        with open(features_path, 'rb') as f:\n",
    "            features_data = pickle.load(f)\n",
    "        \n",
    "        instance.features = features_data['features']\n",
    "        instance.image_paths = features_data['image_paths']\n",
    "        instance.asins = features_data['asins']\n",
    "        \n",
    "        print(f\"Loaded {len(instance.features)} indexed features\")\n",
    "        return instance\n",
    "\n",
    "\n",
    "# Example usage for saving the model\n",
    "if __name__ == \"__main__\":\n",
    "    # Directory containing all product images\n",
    "    image_directory = \"downloaded_images\"\n",
    "    \n",
    "    # Path to CSV file with product metadata\n",
    "    product_data_path = \"data_scrape\\\\merged_data.csv\"\n",
    "    \n",
    "    # Directory to save the model\n",
    "    save_directory = \"visual_search_model\"\n",
    "    \n",
    "    # Initialize and train visual search system\n",
    "    search_system = ProductVisualSearch(image_directory, product_data_path)\n",
    "    \n",
    "    # Save the model and features\n",
    "    search_system.save_model(save_directory)\n",
    "    \n",
    "    # Later, you can load the model without retraining\n",
    "    loaded_system = ProductVisualSearch.load_model(save_directory, product_data_path)\n",
    "    \n",
    "    # Use the loaded model for search\n",
    "    query_image = \"laptop image.jpeg\"\n",
    "    results = loaded_system.search(query_image, top_k=5)\n",
    "    loaded_system.print_results(results)\n",
    "    loaded_system.visualize_results(query_image, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
